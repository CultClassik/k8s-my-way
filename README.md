# Kubernetes the "hard" way with Vagrant and Ansible

## Requirements
A system with enough CPU, RAM and disk to host the desired number of VMs in your Kubernetes cluster.

Tested operating systems:
* Mac OSX
* Ubuntu Linux

Old folders from original method that used Bash and Puppet instead of Ansible left for reference
* puppet
* shell

## Setup (from root of this repo, on the vbox host)
1. Set variables in vagrant.yml as needed
* local_user: chris
* github_userid: cultclassik
* user_id: vagrant
2. run `vagrant up` 
* Will generate an Ansible inventory file at `./.vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory`
3. Run `ansible-playbook -i ./.vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory ./ansible/main.yml`
* Generates all TLS certificates
* Distributes TLS certs and kube conf files
* Installs and configures kubectl on all systems
* Installs etcd, controller and node components
* Creates haproxy container on the vbox host to serve as the k8s API proxy

## Vagrantfile
* Will create as many controllers and nodes as defined
* VMs will be created as linked clones to conserve disk space
* Will run the Ansible provisioner on all VMs after the last VM has been provisioned

## Individual plays
All plays in the "plays" folder will perform the actions for individual components i.e. vbox host, etcd hosts, nodes, controllers.

## Ansible Inventory file example generated by Vagrant
```
# Generated by Vagrant

kn2 ansible_host=127.0.0.1 ansible_port=2203 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kn2/virtualbox/private_key'
kc3 ansible_host=127.0.0.1 ansible_port=2201 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kc3/virtualbox/private_key'
kc2 ansible_host=127.0.0.1 ansible_port=2200 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kc2/virtualbox/private_key'
kc1 ansible_host=127.0.0.1 ansible_port=2222 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kc1/virtualbox/private_key'
kn3 ansible_host=127.0.0.1 ansible_port=2204 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kn3/virtualbox/private_key'
kn4 ansible_host=127.0.0.1 ansible_port=2205 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kn4/virtualbox/private_key'
kn1 ansible_host=127.0.0.1 ansible_port=2202 ansible_user='vagrant' ansible_ssh_private_key_file='/home/chris/k8s-my-way/.vagrant/machines/kn1/virtualbox/private_key'

[k8s_etcd]
kc1
kc2
kc3

[k8s_controller]
kc1
kc2
kc3

[k8s_node]
kn1
kn2
kn3
kn4

[all:vars]
k8s_interface=enp0s9
k8s_version=1.18.0
kubectl_download_filetype=archive
kubectl_checksum_archive=sha512:594ca3eadc7974ec4d9e4168453e36ca434812167ef8359086cd64d048df525b7bd46424e7cc9c41e65c72bda3117326ba1662d1c9d739567f10f5684fd85bee
private_if=enp0s9
public_if=enp0s8
local_id=chris
user_id=vagrant
kube_conf_dir=/home/{{ user_id }}/k8s
k8s_conf_files_dir=/home/{{ local_id }}/k8s-conf
cluster_cidr=176.16.13.0/24
pod_cidr=192.168.10.0/24
```

------

## TODO
Health checks need to be setup with the API server at https://127.0.0.1:6443/healthz
Ensure shell commands include a "creates" when possible
